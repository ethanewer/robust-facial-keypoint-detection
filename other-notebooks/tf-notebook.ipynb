{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('facial-keypoints-detection/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full = df.drop(columns=['Image']).values.astype(np.float32)\n",
    "x_full = [[int(n) for n in img_str.split()] for img_str in df['Image']]\n",
    "x_full = np.array(x_full, dtype=np.float32).reshape((-1, 96, 96, 1)) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img, keypoint_sets):\n",
    "    plt.imshow(img, cmap='grey')\n",
    "    for y in keypoint_sets:\n",
    "        key_points = y.reshape((-1, 2))\n",
    "        plt.scatter(key_points[:, 0], key_points[:, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_full[0], [y_full[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    x_full, \n",
    "    y_full,\n",
    "    test_size=0.125,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "imputer = KNNImputer()\n",
    "y_train_full = imputer.fit_transform(y_train_full)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, \n",
    "    y_train_full,\n",
    "    test_size=0.15,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(f'{len(x_train)} train, {len(x_valid)} valid, {len(x_test)} test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import models, layers, losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(weights_path=None):\n",
    "    model = models.Sequential((\n",
    "        layers.Input(shape=(96, 96, 1)),\n",
    "        layers.Conv2D(64, (3, 3), \n",
    "                    padding='same', \n",
    "                    activation=tf.nn.relu, \n",
    "                    use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(32, (3, 3),\n",
    "                    padding='same', \n",
    "                    activation=tf.nn.relu, \n",
    "                    use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(16, (3, 3), \n",
    "                    padding='same', \n",
    "                    activation=tf.nn.relu, \n",
    "                    use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=tf.nn.relu),\n",
    "        layers.Dense(30),\n",
    "    ))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    model.compile(loss=losses.mean_squared_error, \n",
    "                  metrics=[tf.metrics.R2Score()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterate(x, y, batch_size):\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    for s in range(0, y.shape[0], batch_size):\n",
    "        idxs = permutation[s:s + batch_size]\n",
    "        yield tf.convert_to_tensor(x[idxs]), tf.convert_to_tensor(y[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model('./checkpoints/model1.weights.h5')\n",
    "optimizer = optimizers.Adam(learning_rate=0.001, weight_decay=0.1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        l = model.loss(y, y_pred)\n",
    "    grads = tape.gradient(l, model.trainable_variables)\n",
    "    optimizer.apply(grads, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(100):\n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print('epoch:', epoch + 1)\n",
    "#     for x, y in batch_iterate(x_train, y_train, batch_size=100):\n",
    "#         train_step(x, y)\n",
    "#     optimizer.learning_rate *= 0.99\n",
    "\n",
    "# model.save_weights('./checkpoints/model0.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_full[:1]).numpy()\n",
    "plot(x_full[0], [y_full[0], y_pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacking the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(model, x, y, eps):\n",
    "    delta = tf.Variable(tf.zeros_like(x))\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x + delta)\n",
    "        l = model.loss(y, y_pred)\n",
    "    grad = tape.gradient(l, delta)\n",
    "    return eps * tf.sign(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = fgsm(model, x_full[:1], y_full[:1], 0.01)\n",
    "y_pred = model(x_full[:1] + delta).numpy()\n",
    "plot(x_full[0] + delta[0], [y_full[0], y_pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(model, x, y, eps, alpha=0.001, n_iters=100):\n",
    "    delta = tf.Variable(tf.zeros_like(x))\n",
    "\n",
    "    @tf.function\n",
    "    def train_step():\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x + delta)\n",
    "            l = model.loss(y, y_pred)\n",
    "        grad = tape.gradient(l, delta)\n",
    "        delta.assign_add(alpha * grad)\n",
    "        delta.assign(tf.clip_by_value(delta, -eps, eps))\n",
    "    \n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        train_step()\n",
    "\n",
    "    return delta.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pgd(model, x_full[:1], y_full[:1], 0.01)\n",
    "y_pred = model(x_full[:1] + delta).numpy()\n",
    "plot(x_full[0] + delta[0], [y_full[0], y_pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_fgsm = x_valid + fgsm(model, x_valid, y_valid, 0.01)\n",
    "x_valid_pgd = x_valid  + pgd(model, x_valid, y_valid, 0.01)\n",
    "\n",
    "print('no attack:')\n",
    "_ = model.evaluate(x_valid, y_valid)\n",
    "print('fgsm attack:')\n",
    "_ = model.evaluate(x_valid_fgsm, y_valid)\n",
    "print('pgd attack:')\n",
    "_ = model.evaluate(x_valid_pgd, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "optimizer = optimizers.Adam(learning_rate=0.001, weight_decay=0.1)\n",
    "batch_size = 100\n",
    "delta = tf.Variable(tf.zeros((batch_size, 96, 96, 1)))        \n",
    "eps = tf.Variable(0.005)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def adversarial_train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        l = model.loss(y, y_pred)\n",
    "    grads = tape.gradient(l, model.trainable_variables)\n",
    "    optimizer.apply(grads, model.trainable_variables)\n",
    "\n",
    "    delta.assign(tf.zeros_like(delta))\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x + delta)\n",
    "        l = model.loss(y, y_pred)\n",
    "    grad = tape.gradient(l, delta)\n",
    "    x += eps * tf.sign(grad)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        l = model.loss(y, y_pred)\n",
    "    grads = tape.gradient(l, model.trainable_variables)\n",
    "    optimizer.apply(grads, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_fgsm = x_valid + fgsm(model, x_valid, y_valid, 0.01)\n",
    "\n",
    "print('no attack:')\n",
    "_ = model.evaluate(x_valid, y_valid)\n",
    "print('fgsm attack:')\n",
    "_ = model.evaluate(x_valid_fgsm, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch:', epoch + 1)\n",
    "    for x, y in batch_iterate(x_train, y_train, batch_size=batch_size):\n",
    "        if len(x) != batch_size:\n",
    "            continue\n",
    "        adversarial_train_step(x, y)\n",
    "    optimizer.learning_rate *= 0.99\n",
    "    eps.assign_add(0.0001)\n",
    "\n",
    "model.save_weights('./checkpoints/robust_model0.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_fgsm = x_valid + fgsm(model, x_valid, y_valid, 0.01)\n",
    "\n",
    "print('no attack:')\n",
    "_ = model.evaluate(x_valid, y_valid)\n",
    "print('fgsm attack:')\n",
    "_ = model.evaluate(x_valid_fgsm, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_full[0:1]).numpy()\n",
    "plot(x_full[0], [y_full[0], y_pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = fgsm(model, x_full[:1], y_full[:1], 0.01)\n",
    "y_pred = model(x_full[:1] + delta).numpy()\n",
    "plot(x_full[0] + delta[0], [y_full[0], y_pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
