{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('facial-keypoints-detection/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full = df.drop(columns=['Image']).values.astype(np.float32)\n",
    "x_full = [[int(n) for n in img_str.split()] for img_str in df['Image']]\n",
    "x_full = np.array(x_full, dtype=np.float32).reshape((-1, 96, 96))\n",
    "x_full = np.array([cv2.resize(img, (224, 224), cv2.INTER_CUBIC) for img in x_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img, keypoint_sets):\n",
    "    plt.imshow(img, cmap='grey')\n",
    "    for y in keypoint_sets:\n",
    "        key_points = y.reshape((-1, 2))\n",
    "        key_points *= img.shape[0] / 96\n",
    "        plt.scatter(key_points[:, 0], key_points[:, 1])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_plot(imgs, key_point_sets, cols=4):\n",
    "    n = len(imgs)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    for i in range(n):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(imgs[i], cmap='grey')\n",
    "        plt.axis('off')\n",
    "        key_points = key_point_sets[i].reshape((-1, 2))\n",
    "        key_points *= imgs.shape[1] / 96\n",
    "        plt.scatter(key_points[:, 0], key_points[:, 1], s=8, c='lime')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_plot(x_full[:12], y_full[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    x_full, \n",
    "    y_full,\n",
    "    test_size=0.125,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "imputer = KNNImputer()\n",
    "y_train_full = imputer.fit_transform(y_train_full)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, \n",
    "    y_train_full,\n",
    "    test_size=0.15,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(f'{len(x_train)} train, {len(x_valid)} valid, {len(x_test)} test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "DEVICE = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np2torch(x, device=DEVICE):\n",
    "    return torch.from_numpy(x).to(device)\n",
    "\n",
    "\n",
    "def torch2np(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def transform_imgs(x, device=DEVICE):\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.reshape((-1, 1, 224, 224))\n",
    "    x = torch.repeat_interleave(x, 3, dim=1)\n",
    "    x = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(x)\n",
    "    return x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet(weights_path=None, frozen=True):\n",
    "    if weights_path:\n",
    "        model = resnet18()\n",
    "        model.fc = nn.Linear(model.fc.in_features, 30)\n",
    "        model.load_state_dict(torch.load(weights_path))\n",
    "        if frozen:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            model.fc.weight.requires_grad = True\n",
    "            model.fc.bias.requires_grad = True\n",
    "    else:\n",
    "        model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        if frozen:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        model.fc = nn.Linear(model.fc.in_features, 30)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterate(x, y, batch_size, device=DEVICE):\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    for s in range(0, y.shape[0], batch_size):\n",
    "        idxs = permutation[s:s + batch_size]\n",
    "        yield transform_imgs(x[idxs]), np2torch(y[idxs], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y, max_batches=0, device=DEVICE):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    r2_sum = 0\n",
    "    n_batches = 0\n",
    "    for x, y in batch_iterate(x, y, batch_size=100, device=device):\n",
    "        if max_batches and n_batches >= max_batches:\n",
    "            break\n",
    "        y_pred = model(x)\n",
    "        loss = F.mse_loss(y_pred, y).item()\n",
    "        var = torch.mean(torch.square(y - torch.mean(y, dim=0))).item()\n",
    "        r2 = 1 - loss / var\n",
    "        loss_sum += loss\n",
    "        r2_sum += r2\n",
    "        n_batches += 1\n",
    "    print(f'loss: {loss_sum / n_batches:.3f}, R^2: {r2_sum / n_batches:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_resnet(frozen=False).to(DEVICE)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(opt, step_size=1, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x, y in batch_iterate(x_train, y_train, batch_size=100):\n",
    "        opt.zero_grad()\n",
    "        loss = F.mse_loss(model(x), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'[epoch {epoch + 1}]')\n",
    "        print('    train: ', end=''); evaluate(model, x_train, y_train, max_batches=5)\n",
    "        print('    valid: ', end=''); evaluate(model, x_valid, y_valid, max_batches=5)\n",
    "    \n",
    "torch.save(model.state_dict(), 'checkpoints/resnet1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch2np(model(transform_imgs(x_full[:12])).clip(0, 95))\n",
    "multi_plot(x_full[:12], y_pred[:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacking the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(model, x, y, eps):\n",
    "    delta = torch.zeros_like(x, requires_grad=True)\n",
    "    loss = F.mse_loss(model(x + delta), y)\n",
    "    loss.backward()\n",
    "    return eps * torch.sign(delta.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(model, x, y, eps, alpha=0.1, n_iters=100):\n",
    "    delta = torch.zeros_like(x, requires_grad=True)\n",
    "    for _ in range(n_iters):\n",
    "        loss = F.mse_loss(model(x + delta), y)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            delta += alpha * delta.grad\n",
    "            delta.clip_(-eps, eps)\n",
    "            delta.grad.zero_()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fgsm(model, x, y, eps, device=DEVICE):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    r2_sum = 0\n",
    "    n_batches = 0\n",
    "    for x, y in batch_iterate(x, y, batch_size=100, device=device):\n",
    "        x += fgsm(model, x, y, eps)\n",
    "        y_pred = model(x)\n",
    "        loss = F.mse_loss(y_pred, y).item()\n",
    "        var = torch.mean(torch.square(y - torch.mean(y, dim=0))).item()\n",
    "        r2 = 1 - loss / var\n",
    "        loss_sum += loss\n",
    "        r2_sum += r2\n",
    "        n_batches += 1\n",
    "    print(f'loss: {loss_sum / n_batches:.3f}, R^2: {r2_sum / n_batches:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pgd(model, x, y, eps, device=DEVICE):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    r2_sum = 0\n",
    "    n_batches = 0\n",
    "    for x, y in batch_iterate(x, y, batch_size=100, device=device):\n",
    "        x += pgd(model, x, y, eps)\n",
    "        y_pred = model(x)\n",
    "        loss = F.mse_loss(y_pred, y).item()\n",
    "        var = torch.mean(torch.square(y - torch.mean(y, dim=0))).item()\n",
    "        r2 = 1 - loss / var\n",
    "        loss_sum += loss\n",
    "        r2_sum += r2\n",
    "        n_batches += 1\n",
    "    print(f'loss: {loss_sum / n_batches:.3f}, R^2: {r2_sum / n_batches:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = fgsm(model, transform_imgs(x_full[:12]), np2torch(y_full[:12]), 0.001)\n",
    "y_pred = torch2np(model(transform_imgs(x_full[:12]) + delta).clip(0, 95))\n",
    "multi_plot(x_full[:12], y_pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pgd(model, transform_imgs(x_full[:12]), np2torch(y_full[:12]), 0.001)\n",
    "y_pred = torch2np(model(transform_imgs(x_full[:12]) + delta).clip(0, 95))\n",
    "multi_plot(x_full[:12], y_pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('no attack:')\n",
    "evaluate(model, x_valid, y_valid)\n",
    "print('fgsm attack:')\n",
    "evaluate_fgsm(model, x_valid, y_valid, 0.01)\n",
    "print('pgd attack:')\n",
    "evaluate_pgd(model, x_valid, y_valid, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_model = get_resnet(frozen=False).to(DEVICE)\n",
    "opt = optim.Adam(robust_model.parameters(), lr=0.001, weight_decay=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(opt, step_size=1, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_model.train()\n",
    "\n",
    "delta = torch.zeros((100, 3, 224, 224), requires_grad=True, device=DEVICE)\n",
    "eps = 0.005\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(100):\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('epoch:', epoch + 1)\n",
    "        \n",
    "    for x, y in batch_iterate(x_train, y_train, batch_size=batch_size):\n",
    "        if len(x) != batch_size:\n",
    "            continue\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = F.mse_loss(robust_model(x + delta), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x += eps * delta.grad.sign_()\n",
    "            delta.grad.zero_()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = F.mse_loss(robust_model(x), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    eps += 0.0001\n",
    "    scheduler.step()\n",
    "    \n",
    "torch.save(robust_model.state_dict(), 'checkpoints/robust_model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('no attack:')\n",
    "evaluate(robust_model, x_valid, y_valid)\n",
    "print('fgsm attack:')\n",
    "evaluate_fgsm(robust_model, x_valid, y_valid, 0.01)\n",
    "print('pgd attack:')\n",
    "evaluate_pgd(robust_model, x_valid, y_valid, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = fgsm(robust_model, transform_imgs(x_full[:12]), np2torch(y_full[:12]), 0.01)\n",
    "y_pred = torch2np(robust_model(transform_imgs(x_full[:12]) + delta).clip(0, 95))\n",
    "multi_plot(x_full[:12, 0] + torch2np(delta)[:12], y_pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pgd(robust_model, transform_imgs(x_full[:12]), np2torch(y_full[:12]), 0.01)\n",
    "y_pred = torch2np(robust_model(transform_imgs(x_full[:12]) + delta).clip(0, 95))\n",
    "multi_plot(x_full[:12, 0] + torch2np(delta)[:12], y_pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
