{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import nullcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"facial-keypoints-detection/training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full = df.drop(columns=[\"Image\"]).values.astype(np.float32)\n",
    "x_full = [[int(n) for n in img_str.split()] for img_str in df[\"Image\"]]\n",
    "x_full = np.array(x_full, dtype=np.float32).reshape((-1, 1, 96, 96)) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img, keypoint_sets):\n",
    "    plt.imshow(img, cmap=\"grey\")\n",
    "    for y in keypoint_sets:\n",
    "        key_points = y.reshape((-1, 2))\n",
    "        plt.scatter(key_points[:, 0], key_points[:, 1])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_plot(imgs, key_point_sets, cols=4):\n",
    "    n = len(imgs)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    for i in range(n):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(imgs[i], cmap=\"grey\")\n",
    "        plt.axis('off')\n",
    "        key_points = key_point_sets[i].reshape((-1, 2))\n",
    "        key_points *= imgs.shape[1] / 96\n",
    "        plt.scatter(key_points[:, 0], key_points[:, 1], s=8, c=\"lime\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_plot(x_full[:12, 0], y_full[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    x_full, \n",
    "    y_full,\n",
    "    test_size=0.125,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "imputer = KNNImputer()\n",
    "y_train_full = imputer.fit_transform(y_train_full)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_full, \n",
    "    y_train_full,\n",
    "    test_size=0.15,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(f\"{len(x_train)} train, {len(x_val)} val, {len(x_test)} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "compile_model = device == \"cpu\" or device == \"cuda\"\n",
    "\n",
    "context = torch.autocast(device) if device == \"cuda\" else nullcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np2torch(x, device=device):\n",
    "    return torch.from_numpy(x).to(device)\n",
    "\n",
    "\n",
    "def torch2np(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 30)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
    "        x = x.reshape((-1, 9216))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterate(x, y, batch_size, device=device):\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    for s in range(0, y.shape[0], batch_size):\n",
    "        idxs = permutation[s:s + batch_size]\n",
    "        yield np2torch(x[idxs], device), np2torch(y[idxs], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y, device=device):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    r2_sum = 0\n",
    "    n_batches = 0\n",
    "    for x, y in batch_iterate(x, y, batch_size=100, device=device):\n",
    "        y_pred = model(x)\n",
    "        loss = F.mse_loss(y_pred, y).item()\n",
    "        var = torch.mean(torch.square(y - torch.mean(y, dim=0))).item()\n",
    "        r2 = 1 - loss / var\n",
    "        loss_sum += loss\n",
    "        r2_sum += r2\n",
    "        n_batches += 1\n",
    "    print(f\"loss: {loss_sum / n_batches:.3f}, R^2: {r2_sum / n_batches:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoints/model0.pth\"))\n",
    "if compile_model:\n",
    "    model = torch.compile(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()\n",
    "\n",
    "# for epoch in range(200):\n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print('epoch:', epoch + 1)\n",
    "\n",
    "#     for x, y in batch_iterate(x_train, y_train, batch_size=100):\n",
    "#         optimizer.zero_grad()\n",
    "#         with context:\n",
    "#             loss = F.mse_loss(model(x), y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "# torch.save(model.state_dict(), \"checkpoints/model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch2np(model(np2torch(x_full[:12])).clip(0, 95))\n",
    "multi_plot(x_full[:12, 0], y_pred[:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacking the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(model, x, y, eps):\n",
    "    delta = torch.zeros_like(x, requires_grad=True)\n",
    "    with context:\n",
    "        loss = F.mse_loss(model(x + delta), y)\n",
    "    loss.backward()\n",
    "    return eps * torch.sign(delta.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(model, x, y, eps, alpha=0.5, n_iters=50):\n",
    "    delta = torch.zeros_like(x, requires_grad=True)\n",
    "    for _ in range(n_iters):\n",
    "        with context:\n",
    "            loss = F.mse_loss(model(x + delta), y)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            delta += alpha * delta.grad\n",
    "            delta.clip_(-eps, eps)\n",
    "            delta.grad.zero_()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fgsm(model, x, y, eps, device=device):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    r2_sum = 0\n",
    "    n_batches = 0\n",
    "    for x, y in batch_iterate(x, y, batch_size=100, device=device):\n",
    "        x += fgsm(model, x, y, eps)\n",
    "        y_pred = model(x)\n",
    "        loss = F.mse_loss(y_pred, y).item()\n",
    "        var = torch.mean(torch.square(y - torch.mean(y, dim=0))).item()\n",
    "        r2 = 1 - loss / var\n",
    "        loss_sum += loss\n",
    "        r2_sum += r2\n",
    "        n_batches += 1\n",
    "    print(f\"loss: {loss_sum / n_batches:.3f}, R^2: {r2_sum / n_batches:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pgd(model, x, y, eps, device=device):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    r2_sum = 0\n",
    "    n_batches = 0\n",
    "    for x, y in batch_iterate(x, y, batch_size=100, device=device):\n",
    "        x += pgd(model, x, y, eps)\n",
    "        y_pred = model(x)\n",
    "        loss = F.mse_loss(y_pred, y).item()\n",
    "        var = torch.mean(torch.square(y - torch.mean(y, dim=0))).item()\n",
    "        r2 = 1 - loss / var\n",
    "        loss_sum += loss\n",
    "        r2_sum += r2\n",
    "        n_batches += 1\n",
    "    print(f\"loss: {loss_sum / n_batches:.3f}, R^2: {r2_sum / n_batches:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = fgsm(model, np2torch(x_full[:12]), np2torch(y_full[:12]), 0.01)\n",
    "y_pred = torch2np(model(np2torch(x_full[:12]) + delta).clip(0, 95))\n",
    "multi_plot(x_full[:12, 0] + torch2np(delta)[:12, 0], y_pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pgd(model, np2torch(x_full[:12]), np2torch(y_full[:12]), 0.01)\n",
    "y_pred = torch2np(model(np2torch(x_full[:12]) + delta).clip(0, 95))\n",
    "multi_plot(x_full[:12, 0] + torch2np(delta)[:12, 0], y_pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"no attack:\", end=\"\\n    \")\n",
    "evaluate(model, x_val, y_val)\n",
    "print(\"fgsm attack:\", end=\"\\n    \")\n",
    "evaluate_fgsm(model, x_val, y_val, 0.01)\n",
    "print(\"pgd attack:\", end=\"\\n    \")\n",
    "evaluate_pgd(model, x_val, y_val, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Model FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust_model_fgsm = CNN().to(device)\n",
    "# robust_model_fgsm.load_state_dict(torch.load(\"checkpoints/robust_model_fgsm0.pth\"))\n",
    "# if compile_model:\n",
    "#     robust_model_fgsm = torch.compile(robust_model_fgsm)\n",
    "\n",
    "# optimizer = optim.Adam(robust_model_fgsm.parameters(), lr=0.001, weight_decay=0.1)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust_model_fgsm.train()\n",
    "\n",
    "# delta = torch.zeros((100, 1, 96, 96), requires_grad=True, device=device)\n",
    "# eps = 0.005\n",
    "# batch_size = 100\n",
    "\n",
    "# for epoch in range(200):\n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print('epoch:', epoch + 1)\n",
    "        \n",
    "#     for x, y in batch_iterate(x_train, y_train, batch_size=batch_size):\n",
    "#         if len(x) != batch_size:\n",
    "#             continue\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         with context:\n",
    "#             loss = F.mse_loss(robust_model_fgsm(x + delta), y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             x += eps * delta.grad.sign_()\n",
    "#             delta.grad.zero_()\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         with context:\n",
    "#             loss = F.mse_loss(robust_model_fgsm(x), y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     eps += 0.0001\n",
    "#     scheduler.step()\n",
    "    \n",
    "# torch.save(robust_model_fgsm.state_dict(), \"checkpoints/robust_model_fgsm0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"no attack:\", end=\"\\n    \")\n",
    "# evaluate(robust_model_fgsm, x_val, y_val)\n",
    "# print(\"fgsm attack:\", end=\"\\n    \")\n",
    "# evaluate_fgsm(robust_model_fgsm, x_val, y_val, 0.01)\n",
    "# print(\"pgd attack:\", end=\"\\n    \")\n",
    "# evaluate_pgd(robust_model_fgsm, x_val, y_val, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Model PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_loss(model, x, y, eps, device=device):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    n_batches = 0\n",
    "    for x, y in batch_iterate(x, y, batch_size=100, device=device):\n",
    "        x += pgd(model, x, y, eps)\n",
    "        y_pred = model(x)\n",
    "        loss = F.mse_loss(y_pred, y).item()\n",
    "        loss_sum += loss\n",
    "        n_batches += 1\n",
    "    return loss_sum / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_model_pgd = CNN().to(device)\n",
    "robust_model_pgd.load_state_dict(torch.load(\"checkpoints/robust_model_pgd0.pth\"))\n",
    "if compile_model:\n",
    "    robust_model_pgd = torch.compile(robust_model_pgd)\n",
    "\n",
    "optimizer = optim.Adam(robust_model_pgd.parameters(), lr=0.001, weight_decay=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_model_pgd.train()\n",
    "\n",
    "eps_max = 0.015\n",
    "eps = 0.001\n",
    "batch_size = 100\n",
    "best_pgd_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(200):\n",
    "    for x, y in batch_iterate(x_train, y_train, batch_size=batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        with context:\n",
    "            loss = F.mse_loss(robust_model_pgd(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        x += pgd(robust_model_pgd, x, y, eps)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with context:\n",
    "            loss = F.mse_loss(robust_model_pgd(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if eps < eps_max:\n",
    "        eps += 0.0001\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 25 == 0:\n",
    "        pgd_val_loss = pgd_loss(robust_model_pgd, x_val, y_val, 0.1)\n",
    "        print(f\"epoch {epoch + 1}, loss: {pgd_val_loss:.3f}\")\n",
    "        if pgd_val_loss < best_pgd_val_loss:\n",
    "            best_pgd_val_loss = pgd_val_loss\n",
    "            torch.save(robust_model_pgd.state_dict(), \"checkpoints/robust_model_pgd0.pth\")\n",
    "            print(\"    model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"no attack:\", end=\"\\n    \")\n",
    "evaluate(robust_model_pgd, x_val, y_val)\n",
    "print(\"fgsm attack:\", end=\"\\n    \")\n",
    "evaluate_fgsm(robust_model_pgd, x_val, y_val, 0.01)\n",
    "print(\"pgd attack:\", end=\"\\n    \")\n",
    "evaluate_pgd(robust_model_pgd, x_val, y_val, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = fgsm(robust_model_pgd, np2torch(x_full[:12]), np2torch(y_full[:12]), 0.01)\n",
    "y_pred = torch2np(robust_model_pgd(np2torch(x_full[:12]) + delta).clip(0, 95))\n",
    "multi_plot(x_full[:12, 0] + torch2np(delta)[:12, 0], y_pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pgd(robust_model_pgd, np2torch(x_full[:12]), np2torch(y_full[:12]), 0.01)\n",
    "y_pred = torch2np(robust_model_pgd(np2torch(x_full[:12]) + delta).clip(0, 95))\n",
    "multi_plot(x_full[:12, 0] + torch2np(delta)[:12, 0], y_pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
